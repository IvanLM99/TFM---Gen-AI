{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TFM - Latent space comparison between different generative models (VAE, GAN, StyleGAN...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(0);\n",
    "# Set random seed for reproducibility\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "**GAN Discriminator and Generator architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on ``netG`` and ``netD``\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nc=1, nz=100, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "       \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8,  kernel_size=3, stride=2, padding=1,output_padding=1),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4,  kernel_size=3, stride=2, padding=1,output_padding=1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf,  kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, nc, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "      \n",
    "        return self.main(input)\n",
    "       \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=1, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(nc, ndf, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*2, ndf * 4,kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf*4, ndf * 4,kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, nc, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class MyMnist(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.img_dir = os.listdir(path)\n",
    "        self.transform = transform \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for name in self.img_dir:\n",
    "            img_path = os.path.join(self.path, name)\n",
    "            image = read_image(img_path) / 255\n",
    "            image = image.type(torch.FloatTensor)\n",
    "            label = float(img_path.split(\"_\")[1][0])\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            self.images.append(image)\n",
    "            self.labels.append(int(label))\n",
    "    def __len__(self):\n",
    "        return len(self.img_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(MyMnist(\"../hdd/data/MNIST/train/\"), batch_size=64, shuffle=True)\n",
    "data_loader_val = torch.utils.data.DataLoader(MyMnist(\"../hdd/data/MNIST/test/\"), batch_size=64, shuffle=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 32\n",
    "tb = torch.zeros((64,1,im_size,im_size))\n",
    "\n",
    "test_labels = [\"patito\", \"random\", \"colze\", \"ma\", \"pulmo\",\"buida\"]\n",
    "patito = cv2.imread(\"../hdd/data/patito.png\", cv2.IMREAD_GRAYSCALE)\n",
    "colze = cv2.imread(\"../hdd/data/colze.png\", cv2.IMREAD_GRAYSCALE)\n",
    "ma = cv2.imread(\"../hdd/data/ma.png\", cv2.IMREAD_GRAYSCALE)\n",
    "pulmo = cv2.imread(\"../hdd/data/pulmo.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "patito =  cv2.resize(patito, (im_size,im_size))\n",
    "colze =  cv2.resize(colze, (im_size,im_size))\n",
    "ma =  cv2.resize(ma, (im_size,im_size))\n",
    "pulmo =  cv2.resize(pulmo, (im_size,im_size))\n",
    "r = np.random.rand(im_size,im_size)\n",
    "\n",
    "tb[0,:,:,:] = torch.from_numpy(patito) / 255.0\n",
    "tb[1,:,:,:] = torch.from_numpy(r) / 255.0\n",
    "tb[2,:,:,:] = torch.from_numpy(colze) / 255.0\n",
    "tb[3,:,:,:] = torch.from_numpy(ma) / 255.0\n",
    "tb[4,:,:,:] = torch.from_numpy(pulmo) / 255.0\n",
    "labels_test = [10,11,20,30,40]\n",
    "labels_test.extend([50]*59)\n",
    "test_batch = [[tb, labels_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 64))\n",
    "for jdx, nom in enumerate(test_labels):\n",
    "    axes = fig.add_subplot(1,len(test_labels), jdx+1)\n",
    "    axes.imshow(tb[jdx,0,:,:], cmap='gray');\n",
    "    axes.set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenament"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paràmetres d'entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# latent space dimension\n",
    "ld = 2\n",
    "# number of generator filters\n",
    "ngf = 32\n",
    "#number of discriminator filters\n",
    "ndf = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(nz=ld).to(device)\n",
    "netG.apply(weights_init)\n",
    "#netG.load_state_dict(torch.load('my_nets/netG_epoch_99.pth'))\n",
    "\n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "#netD.load_state_dict(torch.load('my_nets/netD_epoch_99.pth'))\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# setup optimizer\n",
    "batch_size = 64 #Hauría de ser consistent amb el batch size de les dades\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "pbar = tqdm(range(1, num_epochs+1)) # tdqm permet tenir text dinàmic # tdqm permet tenir text dinàmic\n",
    "\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "losses = np.zeros(num_epochs)\n",
    "losses_val = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in pbar:\n",
    "    for i, (data, _) in enumerate(data_loader_train, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad() \n",
    "        data = data.to(device)\n",
    "        batch_size = data.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float,device=device)\n",
    "\n",
    "        output = netD(data)\n",
    "        \n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label) \n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        pbar.set_description('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                   % (epoch, num_epochs, i, len(data_loader_train),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        #if i % 100 == 0:\n",
    "        #    vutils.save_image(real_cpu,'output/real_samples.png' ,normalize=True)\n",
    "        #    fake = netG(fixed_noise)\n",
    "        #    vutils.save_image(fake.detach(),'output/fake_samples_epoch_%03d.png' % (epoch), normalize=True)        \n",
    "    \n",
    "    #torch.save(netG.state_dict(), 'weights/netG_epoch_%d.pth' % (epoch))\n",
    "    #torch.save(netD.state_dict(), 'weights/netD_epoch_%d.pth' % (epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generació de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = ld\n",
    "batch_size = 64\n",
    "fixed_noise = torch.randn(batch_size, latent_size, 1, 1)\n",
    "if torch.cuda.is_available():\n",
    "    fixed_noise = fixed_noise.cuda()\n",
    "    \n",
    "fake_images = netG(fixed_noise)\n",
    "\n",
    "fake_images_np = fake_images.cpu().detach().numpy()\n",
    "\n",
    "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 32, 32)\n",
    "R, C = 8, 8\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(batch_size):\n",
    "  \n",
    "    axes = fig.add_subplot(R, C, i+1)\n",
    "    axes.imshow(fake_images_np[i], cmap='gray');\n",
    "    axes.set_axis_off()\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fixed_noise[:,0,:,:].cpu(),fixed_noise[:,1,:,:].cpu());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projectam l'espai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myspace = [(x, y) for x in np.linspace(-3, 4, 20) for y in np.linspace(-3, 4,20)]\n",
    "myspace = torch.tensor(myspace, dtype=torch.float32)\n",
    "data_loader_myspace = torch.utils.data.DataLoader(list(zip(myspace, [11]*len(myspace))), batch_size=400, shuffle=False)\n",
    "len(myspace)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.eval()\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "for data in data_loader_myspace:\n",
    "    # Forward pass\n",
    "    x, label = data\n",
    "    x = x.to(device)\n",
    "    xx = torch.randn(400, nz, 1, 1, device=device)\n",
    "    xx[:,:,0,0] = x \n",
    "    fake = netG(xx)\n",
    "    for i in range(len(fake[:,0,:,:])):\n",
    "        axes = fig.add_subplot(20,20, i+1)\n",
    "        axes.imshow(fake[i,0,:,:].detach().cpu().numpy(), cmap='gray');\n",
    "        axes.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
